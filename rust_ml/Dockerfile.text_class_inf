# Build Stage
FROM rust:1.92-alpine as builder

WORKDIR /app

WORKDIR /app/rust_ml

# Copy workspace Cargo.toml to help with workspace resolution (optional, but good practice)
# But here we are building a specific crate inside a workspace potentially.
# Let's assume we copy the whole workspace context or at least the relevant parts.
# Since we are inside `rust_ml` workspace, we should copy the root Cargo.toml and the crates.

# Actually, to keep it simple and robust:
# We'll copy the entire rust_ml directory context into the build container.
# This assumes the build context is the `Rest_Python_ML_PE` root or `rust_ml` root.
# Given the user wants to `containerize this pipeline`, let's assume the build context is the repo root.

COPY . /app/rust_ml/

RUN apk add --no-cache \
    build-base \
    clang \
    pkgconf
# Build the release binary for mnist_infer
RUN cargo build --release -p text_classification_infer

# Runtime Stage
FROM alpine:3.23

# Install OpenSSL if needed (Axum/Tokio might need it) and ca-certificates
RUN apk add --no-cache openssl-dev ca-certificates

WORKDIR /app

# Copy binary
COPY --from=builder /app/rust_ml/target/release/text_classification_infer /app/binary

# Copy Model
# Assuming build context is repo root, we need to copy model/mnist_rust/model.mpk
# We'll expect the model to be copied into the container at runtime or build time.
# Let's copy it at build time as requested "containerized pipeline".
COPY model/text_classification_ag_news_rust/config.json /app/model/text_class_rs/config.json
COPY model/text_classification_ag_news_rust/model.mpk /app/model/text_class_rs/model.mpk

# Environment variables
ENV RUST_LOG=info
ENV ARTIFACT_DIR=/app/model/text_class_rs

EXPOSE 9050

CMD ["./binary"]
